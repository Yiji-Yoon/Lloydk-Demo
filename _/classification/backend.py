# backend.py
import os
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient

load_dotenv()

EMBEDDING_MODEL = "text-embedding-3-small"

class RAGRouterService:
    def __init__(
        self,
        qdrant_host: str = "localhost",
        qdrant_port: int = 6333,
        collection_name: str = "ë¯¼ì›ë°ì´í„°",
        openai_api_key: str | None = None,
        upstage_api_key: str | None = None,
    ):
        self.collection_name = collection_name

        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.upstage_api_key = upstage_api_key or os.getenv("UPSTAGE_API_KEY")

        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        if not self.upstage_api_key:
            raise ValueError("UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

        self.oa_client = OpenAI(api_key=self.openai_api_key)
        self.chat_client = OpenAI(
            api_key=self.upstage_api_key,
            base_url="https://api.upstage.ai/v1"
        )
        self.qdrant = QdrantClient(host=qdrant_host, port=qdrant_port)

    def get_embeddings_batch(self, texts: list[str]) -> list[list[float]]:
        resp = self.oa_client.embeddings.create(model=EMBEDDING_MODEL, input=texts)
        return [d.embedding for d in resp.data]

    def rag_search(self, question: str, top_k: int = 5):
        question = (question or "").strip()
        if not question:
            raise ValueError("ì§ˆë¬¸ì´ ë¹„ì–´ ìˆì–´ìš”. ì…ë ¥í•´ ì£¼ì„¸ìš” ğŸ™‚")

        q_embs = self.get_embeddings_batch([question])
        if not q_embs:
            raise RuntimeError("ì„ë² ë”©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”.")

        results = self.qdrant.query_points(
            collection_name=self.collection_name,
            query=q_embs[0],
            limit=top_k,
            with_payload=True
        )
        return results

    def choose_department_with_llm(self, query_text: str, hits) -> str:
        examples_text = ""
        for h in hits.points:
            p = h.payload or {}
            examples_text += (
                f"- ë¬¸ì˜ë‚´ìš©: {p.get('ë¬¸ì˜ë‚´ìš©', '')}\n"
                f"  ë¶€ì„œ: {p.get('ë‹µë³€ë¶€ì„œ', '')}\n\n"
            )

        prompt = f"""
ë„ˆëŠ” ë¯¼ì› ë¼ìš°íŒ… ë³´ì¡° ì‹œìŠ¤í…œì´ë‹¤.

ì•„ë˜ëŠ” ê³¼ê±° ë¯¼ì› ë¬¸ì˜ë‚´ìš©ê³¼ ì‹¤ì œë¡œ ë°°ì •ëœ ë‹´ë‹¹ ë¶€ì„œ ëª©ë¡ì´ë‹¤.

[ê³¼ê±° ë¯¼ì› ì‚¬ë¡€]
{examples_text}

ìœ„ ì‚¬ë¡€ë“¤ì„ ì°¸ê³ í•´ì„œ, ì•„ë˜ 'ìƒˆ ë¯¼ì›'ì— ëŒ€í•´ ê°€ì¥ ì ì ˆí•œ ë‹´ë‹¹ ë¶€ì„œ í•˜ë‚˜ë¥¼ ê³¨ë¼ë¼.
ë°˜ë“œì‹œ ìœ„ ì‚¬ë¡€ì—ì„œ ë“±ì¥í•œ ë¶€ì„œëª… ì¤‘ í•˜ë‚˜ë§Œ ê³ ë¥´ê±°ë‚˜, ì ì ˆí•œ ë¶€ì„œê°€ ì—†ì„ ê²½ìš° 'ì¶”ê°€ë¯¼ì›'ì„ ì¶œë ¥í•˜ë¼.
ê·¸ë¦¬ê³  ê·¸ ì´ìœ ë¥¼ ì‘ì„±í•˜ë¼.

[ìƒˆ ë¯¼ì›]
\"\"\"{query_text}\"\"\"
"""

        resp = self.chat_client.chat.completions.create(
            model="solar-pro2",
            messages=[{"role": "user", "content": prompt}],
        )
        return resp.choices[0].message.content.strip()

    def route(self, question: str, top_k: int = 5):
        """í•œ ë²ˆì—: ê²€ìƒ‰ + ë¶€ì„œ ì„ íƒ"""
        hits = self.rag_search(question, top_k=top_k)
        answer = self.choose_department_with_llm(question, hits)
        return answer, hits
